{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-qHai2252mI",
        "outputId": "dcf4a3fa-bd3b-4fa4-fea8-4ce5f138694f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=22a3e79a35ceb0e789d82e08b32ab1092ac2e88c2b015fe04528c0761ba35a4d\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/dc/11/ec201cd671da62fa9c5cc77078235e40722170ceba231d7598\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n",
            "The following additional packages will be installed:\n",
            "  openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 2 newly installed, 0 to remove and 23 not upgraded.\n",
            "Need to get 36.5 MB of archives.\n",
            "After this operation, 143 MB of additional disk space will be used.\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "(Reading database ... 129504 files and directories currently installed.)\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u352-ga-1~20.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u352-ga-1~20.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u352-ga-1~20.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u352-ga-1~20.04) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u352-ga-1~20.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u352-ga-1~20.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark-asyncactions\n",
            "  Downloading pyspark-asyncactions-0.0.4.tar.gz (12 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pyspark-asyncactions\n",
            "  Building wheel for pyspark-asyncactions (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark-asyncactions: filename=pyspark_asyncactions-0.0.4-py3-none-any.whl size=15940 sha256=8da3c821d04cb94edf1112c7dcfb9b8649762129c694990e5c82ec025a60edd6\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/49/da/970503fa1aad5fe87b3e93f87182f25eb1d883258d0210a1cb\n",
            "Successfully built pyspark-asyncactions\n",
            "Installing collected packages: pyspark-asyncactions\n",
            "Successfully installed pyspark-asyncactions-0.0.4\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5K93ABEy9Zlo",
        "outputId": "799fea34-5882-4428-9fe4-9e73482d9a1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lDh957r_0snm"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, TimestampType\n",
        "from pyspark.sql.functions import col, current_timestamp, to_date, hour, dayofweek\\\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from itertools import combinations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "23/01/23 20:22:40 WARN Utils: Your hostname, Nasers-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.76.238 instead (on interface en0)\n",
            "23/01/23 20:22:40 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "23/01/23 20:22:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
          ]
        }
      ],
      "source": [
        "def create_new_spark_context(appName):\n",
        "    return SparkSession.builder.appName(appName)\\\n",
        "        .master(\"local[*]\").getOrCreate()\n",
        "\n",
        "\n",
        "spark_session = create_new_spark_context(\"LSH\")\n",
        "sc = spark_session.sparkContext\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "schema = StructType([\n",
        "    StructField(\"DEVICE_CODE\", IntegerType(), True),\n",
        "    StructField(\"SYSTEM_ID\", IntegerType(), True),\n",
        "    StructField(\"ORIGINE_CAR_KEY\", StringType(), True),\n",
        "    StructField(\"FINAL_CAR_KEY\", StringType(), True),\n",
        "    StructField(\"CHECK_STATUS_KEY\", IntegerType(), True),\n",
        "    StructField(\"COMPANY_ID\", StringType(), True),\n",
        "    StructField(\"PASS_DAY_TIME\", TimestampType(), True)\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+---------+---------------+-------------+----------------+----------+-------------------+\n",
            "|DEVICE_CODE|SYSTEM_ID|ORIGINE_CAR_KEY|FINAL_CAR_KEY|CHECK_STATUS_KEY|COMPANY_ID|      PASS_DAY_TIME|\n",
            "+-----------+---------+---------------+-------------+----------------+----------+-------------------+\n",
            "|     200501|       81|       10477885|     10477885|               5|       161|2021-06-01 03:54:39|\n",
            "+-----------+---------+---------------+-------------+----------------+----------+-------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = spark_session.read.csv(\n",
        "    '/content/drive/MyDrive/MDA/HW3/TrafficData.csv', header=True, schema=schema)\n",
        "df.show(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGoJ3OTX3Lz_",
        "outputId": "a73c29dd-3bfb-4d39-8b25-bb6493ebf947"
      },
      "outputs": [],
      "source": [
        "traffic_rdd = df.rdd.map(lambda x: ((x[\"FINAL_CAR_KEY\"], x[\"PASS_DAY_TIME\"].date()), x[\"DEVICE_CODE\"]))\\\n",
        "                    .groupByKey()\\\n",
        "                    .map(lambda x: (x[0], set(x[1])))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3g1eaJfrEWAE"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "data": {
            "text/plain": [
              "993"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# make a numpy array with size of the number of distinct device codes\n",
        "device_codes = traffic_rdd.flatMap(lambda x: tuple(x[1])).distinct().collect()\n",
        "num_device = len(device_codes)\n",
        "num_device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3popxXyfMNH",
        "outputId": "a4990ab7-98d5-4aed-9469-3850103cd401"
      },
      "outputs": [],
      "source": [
        "# hash function to map each device code to a number between 0 and num_device\n",
        "device_index_map = {}\n",
        "for i in range(num_device):\n",
        "    device_index_map[device_codes[i]] = i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "path_vec = np.zeros(num_device)\n",
        "indices = np.random.choice(np.arange(num_device), replace=False,\n",
        "                           size=int(num_device * 0.8))\n",
        "path_vec[indices] = 1\n",
        "path = []\n",
        "for i in range(len(path_vec)):\n",
        "    if path_vec[i] == 1:\n",
        "        path.append(device_codes[i])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "794"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "0vwwumdyxvu5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[(('64111706', datetime.date(2021, 6, 1)), 0.8410357816782252),\n",
              " (('8073331', datetime.date(2021, 6, 1)), 0.24832062214018286),\n",
              " (('7633319', datetime.date(2021, 6, 1)), 0.24713098667733246),\n",
              " (('17610801', datetime.date(2021, 6, 1)), 0.2247049817646692),\n",
              " (('29485775', datetime.date(2021, 6, 1)), 0.20865462592433567)]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def path_similarity(x):\n",
        "    similarity = 0\n",
        "    for device_code in x:\n",
        "        similarity += path_vec[device_index_map[device_code]]\n",
        "    return similarity / ((len(x) ** 0.5) * len(path) ** 0.5)\n",
        "\n",
        "\n",
        "most_similar_path = traffic_rdd.map(lambda x: (x[0], path_similarity(x[1]))).sortBy(lambda x: x[-1], ascending=False)\n",
        "most_similar_path.take(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-1., -1.,  1., ..., -1., -1.,  1.],\n",
              "       [-1., -1.,  1., ...,  1., -1., -1.],\n",
              "       [ 1.,  1., -1., ...,  1.,  1., -1.],\n",
              "       ...,\n",
              "       [-1., -1., -1., ..., -1., -1.,  1.],\n",
              "       [ 1.,  1., -1., ...,  1., -1., -1.],\n",
              "       [ 1., -1.,  1., ..., -1., -1.,  1.]])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b = 10\n",
        "r = 15\n",
        "num_planes = b * r\n",
        "\n",
        "random_planes = []\n",
        "for i in range(num_planes):\n",
        "    random_planes.append(np.random.choice([-1.0, 1.0], size=num_device))\n",
        "random_planes = np.array(random_planes)\n",
        "random_planes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "30IC65yoE-5Q"
      },
      "outputs": [],
      "source": [
        "def calculate_hash(x):\n",
        "    items = x\n",
        "    lst = \"\"\n",
        "    for plane in random_planes:\n",
        "        i = 0\n",
        "        for item in items:\n",
        "            i += plane[device_index_map[item]]\n",
        "        z = 1\n",
        "        if i < 0:\n",
        "            z = 0\n",
        "        lst += str(z)\n",
        "    return lst\n",
        "\n",
        "hashed = traffic_rdd.map(lambda x : (x[0], calculate_hash(x[1])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def hash_vector(x):\n",
        "    hash_values = []\n",
        "    for plane in random_planes:\n",
        "        hash_value = 0\n",
        "        for code in x:\n",
        "            hash_value += plane[device_index_map[code]]\n",
        "        hash_values.append(hash_value)\n",
        "    sig = \"\".join([\"1\" if x > 0 else \"0\" for x in hash_values])\n",
        "    return sig\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "hashed_path = hash_vector(path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "9ZNQp001dYnj"
      },
      "outputs": [],
      "source": [
        "def match_hash(x):\n",
        "    first = 0\n",
        "    last = r-1\n",
        "    for i in range(b):\n",
        "        if hashed_path[first:last] == x[first:last]:\n",
        "            return True\n",
        "        first += r\n",
        "        last += r\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "yYwm3JEVJQo6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "data": {
            "text/plain": [
              "645"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "candidates = hashed.filter(lambda x: match_hash(x[1])).collect()\n",
        "len(candidates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFWtIM6Oe2yB",
        "outputId": "80df84c7-91ec-486b-d8dc-d293958d197f"
      },
      "outputs": [],
      "source": [
        "unique_candidates = set(map(lambda x: tuple(x[0]), candidates))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# get the most similar path from the candidates\n",
        "threshold = 0.8\n",
        "\n",
        "most_similar_path = traffic_rdd.map(lambda x: (x[0], (tuple(x[1]), path_similarity(x[1]))))\\\n",
        "    .filter(lambda x: x[0] in unique_candidates)\\\n",
        "    .filter(lambda x: x[1][1] > threshold)\\\n",
        "    .collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(most_similar_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(('64111706', datetime.date(2021, 6, 1)), 0.8410357816782252)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ans = most_similar_path[0]\n",
        "ans[0], ans[1][1]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "myEnv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "17834c5f8fe1aed837634498cfcf8480d7a4681659b9e2d9e3df938711b793bb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
